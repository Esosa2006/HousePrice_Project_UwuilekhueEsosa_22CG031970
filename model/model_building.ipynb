{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f05d718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset shape: (1460, 81)\n",
      "\n",
      "Selected features: ['OverallQual', 'GrLivArea', 'TotalBsmtSF', 'GarageCars', 'YearBuilt', 'Neighborhood']\n",
      "Working dataset shape: (1460, 7)\n",
      "\n",
      "--- Handling Missing Values ---\n",
      "Missing values before:\n",
      "OverallQual     0\n",
      "GrLivArea       0\n",
      "TotalBsmtSF     0\n",
      "GarageCars      0\n",
      "YearBuilt       0\n",
      "Neighborhood    0\n",
      "SalePrice       0\n",
      "dtype: int64\n",
      "\n",
      "Missing values after:\n",
      "OverallQual     0\n",
      "GrLivArea       0\n",
      "TotalBsmtSF     0\n",
      "GarageCars      0\n",
      "YearBuilt       0\n",
      "Neighborhood    0\n",
      "SalePrice       0\n",
      "dtype: int64\n",
      "\n",
      "--- Encoding Categorical Variables ---\n",
      "Neighborhood encoded: 25 unique categories\n",
      "\n",
      "--- Preparing Data for Training ---\n",
      "Features shape: (1460, 6)\n",
      "Target shape: (1460,)\n",
      "\n",
      "Feature columns: ['OverallQual', 'GrLivArea', 'TotalBsmtSF', 'GarageCars', 'YearBuilt', 'Neighborhood_Encoded']\n",
      "\n",
      "Training set size: 1168\n",
      "Test set size: 292\n",
      "\n",
      "--- Training Random Forest Model ---\n",
      "Model training completed!\n",
      "\n",
      "--- Model Evaluation ---\n",
      "\n",
      "Training Set Metrics:\n",
      "  MAE:  $10,408.87\n",
      "  MSE:  $288,990,209.44\n",
      "  RMSE: $16,999.71\n",
      "  R²:   0.9515\n",
      "\n",
      "Test Set Metrics:\n",
      "  MAE:  $18,665.37\n",
      "  MSE:  $876,768,135.81\n",
      "  RMSE: $29,610.27\n",
      "  R²:   0.8857\n",
      "\n",
      "--- Feature Importance ---\n",
      "                Feature  Importance\n",
      "0           OverallQual    0.602041\n",
      "1             GrLivArea    0.191363\n",
      "2           TotalBsmtSF    0.096769\n",
      "4             YearBuilt    0.051862\n",
      "5  Neighborhood_Encoded    0.029750\n",
      "3            GarageCars    0.028216\n",
      "\n",
      "--- Saving Model ---\n",
      "Model saved successfully as 'house_price_model.pkl'\n",
      "\n",
      "--- Verifying Model Load ---\n",
      "\n",
      "Sample predictions from loaded model:\n",
      "  House 1: Predicted=$138,671.44, Actual=$154,500.00\n",
      "  House 2: Predicted=$329,624.98, Actual=$325,000.00\n",
      "  House 3: Predicted=$114,005.95, Actual=$115,000.00\n",
      "  House 4: Predicted=$186,511.78, Actual=$159,000.00\n",
      "  House 5: Predicted=$317,092.60, Actual=$315,500.00\n",
      "\n",
      "✓ Model development completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# House Price Prediction Model\n",
    "# Model Building Notebook\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 1. LOAD DATASET\n",
    "print(\"Loading dataset...\")\n",
    "df = pd.read_csv('Housing.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "\n",
    "# 2. FEATURE SELECTION\n",
    "# Selecting 6 features from the recommended 9\n",
    "selected_features = ['OverallQual', 'GrLivArea', 'TotalBsmtSF', \n",
    "                     'GarageCars', 'YearBuilt', 'Neighborhood']\n",
    "target = 'SalePrice'\n",
    "\n",
    "# Create working dataframe\n",
    "data = df[selected_features + [target]].copy()\n",
    "print(f\"\\nSelected features: {selected_features}\")\n",
    "print(f\"Working dataset shape: {data.shape}\")\n",
    "\n",
    "# 3. DATA PREPROCESSING\n",
    "\n",
    "# 3a. Handle Missing Values\n",
    "print(\"\\n--- Handling Missing Values ---\")\n",
    "print(f\"Missing values before:\\n{data.isnull().sum()}\")\n",
    "\n",
    "# Fill numeric columns with median\n",
    "numeric_cols = ['TotalBsmtSF', 'GarageCars']\n",
    "for col in numeric_cols:\n",
    "    if data[col].isnull().sum() > 0:\n",
    "        data[col].fillna(data[col].median(), inplace=True)\n",
    "\n",
    "# Fill categorical with mode\n",
    "if data['Neighborhood'].isnull().sum() > 0:\n",
    "    data['Neighborhood'].fillna(data['Neighborhood'].mode()[0], inplace=True)\n",
    "\n",
    "print(f\"\\nMissing values after:\\n{data.isnull().sum()}\")\n",
    "\n",
    "# 3b. Encode Categorical Variables\n",
    "print(\"\\n--- Encoding Categorical Variables ---\")\n",
    "le = LabelEncoder()\n",
    "data['Neighborhood_Encoded'] = le.fit_transform(data['Neighborhood'])\n",
    "print(f\"Neighborhood encoded: {len(le.classes_)} unique categories\")\n",
    "\n",
    "# Drop original categorical column\n",
    "data.drop('Neighborhood', axis=1, inplace=True)\n",
    "\n",
    "# 3c. Feature Scaling (Random Forest doesn't require scaling, but including for completeness)\n",
    "# For Random Forest, we won't scale as it's tree-based\n",
    "# If using Linear Regression or SVR, uncomment the scaling code below:\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# feature_cols = [col for col in data.columns if col != target]\n",
    "# data[feature_cols] = scaler.fit_transform(data[feature_cols])\n",
    "\n",
    "# 4. PREPARE DATA FOR TRAINING\n",
    "print(\"\\n--- Preparing Data for Training ---\")\n",
    "X = data.drop(target, axis=1)\n",
    "y = data[target]\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nFeature columns: {list(X.columns)}\")\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining set size: {X_train.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")\n",
    "\n",
    "# 5. TRAIN MODEL\n",
    "print(\"\\n--- Training Random Forest Model ---\")\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=20,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Model training completed!\")\n",
    "\n",
    "# 6. MODEL EVALUATION\n",
    "print(\"\\n--- Model Evaluation ---\")\n",
    "\n",
    "# Predictions\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nTraining Set Metrics:\")\n",
    "print(f\"  MAE:  ${train_mae:,.2f}\")\n",
    "print(f\"  MSE:  ${train_mse:,.2f}\")\n",
    "print(f\"  RMSE: ${train_rmse:,.2f}\")\n",
    "print(f\"  R²:   {train_r2:.4f}\")\n",
    "\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "print(f\"  MAE:  ${test_mae:,.2f}\")\n",
    "print(f\"  MSE:  ${test_mse:,.2f}\")\n",
    "print(f\"  RMSE: ${test_rmse:,.2f}\")\n",
    "print(f\"  R²:   {test_r2:.4f}\")\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\n--- Feature Importance ---\")\n",
    "print(feature_importance)\n",
    "\n",
    "# 7. SAVE MODEL\n",
    "print(\"\\n--- Saving Model ---\")\n",
    "\n",
    "# Save model and label encoder\n",
    "model_data = {\n",
    "    'model': model,\n",
    "    'label_encoder': le,\n",
    "    'feature_columns': list(X.columns),\n",
    "    'metrics': {\n",
    "        'test_mae': test_mae,\n",
    "        'test_rmse': test_rmse,\n",
    "        'test_r2': test_r2\n",
    "    }\n",
    "}\n",
    "\n",
    "joblib.dump(model_data, 'house_price_model.pkl')\n",
    "print(\"Model saved successfully as 'house_price_model.pkl'\")\n",
    "\n",
    "# 8. VERIFY MODEL LOADING\n",
    "print(\"\\n--- Verifying Model Load ---\")\n",
    "loaded_data = joblib.load('house_price_model.pkl')\n",
    "loaded_model = loaded_data['model']\n",
    "\n",
    "# Test prediction\n",
    "sample_prediction = loaded_model.predict(X_test[:5])\n",
    "print(f\"\\nSample predictions from loaded model:\")\n",
    "for i, (pred, actual) in enumerate(zip(sample_prediction, y_test[:5])):\n",
    "    print(f\"  House {i+1}: Predicted=${pred:,.2f}, Actual=${actual:,.2f}\")\n",
    "\n",
    "print(\"\\n✓ Model development completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
